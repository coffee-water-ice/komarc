import streamlit as st
import requests
from bs4 import BeautifulSoup

# âœ… 1ë‹¨ê³„: ISBNìœ¼ë¡œ ì¶œíŒì‚¬ëª… ì¶”ì¶œ
def get_publisher_name_from_isbn(isbn):
    search_url = "https://bnk.kpipa.or.kr/home/v3/addition/search"
    params = {
        "ST": isbn,
        "PG": 1,
        "PG2": 1,
        "DSF": "Y",
        "SO": "weight",
        "DT": "A"
    }
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    try:
        res = requests.get(search_url, params=params, headers=headers)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        first_result_link = soup.select_one("a.book-grid-item")
        if not first_result_link:
            return None, "âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

        detail_href = first_result_link["href"]
        detail_url = f"https://bnk.kpipa.or.kr{detail_href}"
        detail_res = requests.get(detail_url, headers=headers)
        detail_soup = BeautifulSoup(detail_res.text, "html.parser")

        pub_info_tag = detail_soup.find("dt", string="ì¶œíŒì‚¬ / ì„í”„ë¦°íŠ¸")
        if not pub_info_tag:
            return None, "âŒ 'ì¶œíŒì‚¬ / ì„í”„ë¦°íŠ¸' í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        dd_tag = pub_info_tag.find_next_sibling("dd")
        if dd_tag:
            full_text = dd_tag.get_text(strip=True)
            publisher_name = full_text.split("/")[0].strip()
            return publisher_name, None

        return None, "âŒ 'dd' íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}"

# âœ… 2ë‹¨ê³„: ì¶œíŒì‚¬ëª…ìœ¼ë¡œ ì§€ì—­ ì •ë³´ ê²€ìƒ‰ (ê³µì‹ API í˜¸ì¶œ)
def fetch_publisher_region(publisher_name):
    api_url = "https://bnk.kpipa.or.kr/home/v3/addition/adiPblshrInfoList"

    headers = {
        "Content-Type": "application/json",
        "User-Agent": "Mozilla/5.0"
    }

    payload = {
        "pageIndex": 1,
        "searchCondition": "pblshrNm",  # ì¶œíŒì‚¬ëª…ìœ¼ë¡œ ê²€ìƒ‰
        "searchKeyword": publisher_name,
        "searchType": "",
        "searchValue": ""
    }

    try:
        res = requests.post(api_url, headers=headers, json=payload)
        res.raise_for_status()
        json_data = res.json()

        # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì§€ì—­ ì •ë³´ ì¶”ì¶œ
        result_list = json_data.get("resultList", [])
        if result_list:
            region = result_list[0].get("region", "â“ ì§€ì—­ ì •ë³´ ì—†ìŒ")
            return region
        else:
            return "âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

    except Exception as e:
        return f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}"


# âœ… Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ“š ISBN â†’ ì¶œíŒì‚¬ â†’ ì§€ì—­ ì •ë³´ ì¡°íšŒ")

isbn_input = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 9791130649672)")

if st.button("ê²€ìƒ‰"):
    if not isbn_input.strip():
        st.warning("ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ğŸ” ISBNìœ¼ë¡œ ì¶œíŒì‚¬ ì¡°íšŒ ì¤‘..."):
            publisher, error_msg = get_publisher_name_from_isbn(isbn_input.strip())

        if error_msg:
            st.error(error_msg)
        elif publisher:
            st.success(f"âœ… ì¶œíŒì‚¬ëª…: {publisher}")

            with st.spinner("ğŸŒ ì¶œíŒì‚¬ ì§€ì—­ ì¡°íšŒ ì¤‘..."):
                region_info = fetch_publisher_region(publisher)

            if "âŒ" in region_info:
                st.error(region_info)
            else:
                st.success(f"ğŸ™ï¸ ì§€ì—­: {region_info}")
