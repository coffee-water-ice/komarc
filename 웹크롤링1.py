import streamlit as st
import requests
from bs4 import BeautifulSoup

# âœ… 1ë‹¨ê³„: ISBNìœ¼ë¡œ ì¶œíŒì‚¬ëª… ì¶”ì¶œ
def get_publisher_name_from_isbn(isbn):
    search_url = "https://bnk.kpipa.or.kr/home/v3/addition/search"
    params = {
        "ST": isbn,
        "PG": 1,
        "PG2": 1,
        "DSF": "Y",
        "SO": "weight",
        "DT": "A"
    }
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    try:
        res = requests.get(search_url, params=params, headers=headers)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        first_result_link = soup.select_one("a.book-grid-item")
        if not first_result_link:
            return None, "âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"

        detail_href = first_result_link["href"]
        detail_url = f"https://bnk.kpipa.or.kr{detail_href}"
        detail_res = requests.get(detail_url, headers=headers)
        detail_soup = BeautifulSoup(detail_res.text, "html.parser")

        pub_info_tag = detail_soup.find("dt", string="ì¶œíŒì‚¬ / ì„í”„ë¦°íŠ¸")
        if not pub_info_tag:
            return None, "âŒ 'ì¶œíŒì‚¬ / ì„í”„ë¦°íŠ¸' í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        dd_tag = pub_info_tag.find_next_sibling("dd")
        if dd_tag:
            full_text = dd_tag.get_text(strip=True)
            publisher_name = full_text.split("/")[0].strip()
            return publisher_name, None

        return None, "âŒ 'dd' íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"âŒ ì˜ˆì™¸ ë°œìƒ: {e}"

# âœ… 2ë‹¨ê³„: ì¶œíŒì‚¬ëª…ìœ¼ë¡œ ì§€ì—­ ì •ë³´ ê²€ìƒ‰ (API)
def fetch_publisher_region(publisher_name):
    api_url = "https://bnk.kpipa.or.kr/home/v3/addition/adiPblshrInfoList"
    session_id = st.secrets.get("kpipa", {}).get("session_id")

    if not session_id:
        return "âŒ JSESSIONIDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (st.secrets í™•ì¸ í•„ìš”)"

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Cookie": f"JSESSIONID={session_id}"
    }
    params = {"ST": publisher_name}

    try:
        res = requests.get(api_url, headers=headers, params=params)

        content_type = res.headers.get("Content-Type", "")
        if "application/json" not in content_type:
            return f"âŒ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ (Content-Type: {content_type})\nì‘ë‹µ ì˜ˆì‹œ: {res.text[:500]}"

        json_data = res.json()
        if "list" in json_data and len(json_data["list"]) > 0:
            region = json_data["list"][0].get("region", "ì§€ì—­ ì •ë³´ ì—†ìŒ")
            return region
        else:
            return f"âŒ API ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\nJSON ì›ë¬¸: {json_data}"

    except Exception as e:
        return f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}\n\nì‘ë‹µ ì˜ˆì‹œ: {res.text[:500]}"

# âœ… Streamlit ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ“š ISBN â†’ ì¶œíŒì‚¬ â†’ ì§€ì—­ ì •ë³´ ì¡°íšŒ")

isbn_input = st.text_input("ISBNì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 9791130649672)")

if st.button("ê²€ìƒ‰"):
    if not isbn_input.strip():
        st.warning("ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ğŸ” ISBNìœ¼ë¡œ ì¶œíŒì‚¬ ì¡°íšŒ ì¤‘..."):
            publisher, error_msg = get_publisher_name_from_isbn(isbn_input.strip())

        if error_msg:
            st.error(error_msg)
        elif publisher:
            st.success(f"âœ… ì¶œíŒì‚¬ëª…: {publisher}")

            with st.spinner("ğŸŒ ì¶œíŒì‚¬ ì§€ì—­ ì¡°íšŒ ì¤‘..."):
                region_info = fetch_publisher_region(publisher)

            if "âŒ" in region_info:
                st.error(region_info)
            else:
                st.success(f"ğŸ™ï¸ ì§€ì—­: {region_info}")
