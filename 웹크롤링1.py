import streamlit as st
import requests
from bs4 import BeautifulSoup

# 1ï¸âƒ£ ISBN â†’ ì¶œíŒì‚¬ëª… ì¶”ì¶œ
def get_publisher_name_from_isbn(isbn):
    try:
        search_url = "https://bnk.kpipa.or.kr/home/v3/addition/search"
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Referer": "https://bnk.kpipa.or.kr/",
            "Cookie": "JSESSIONID=y8s7sUUBInxudrRrAYiWPM7tZx7CrT4ESkG6ITNRlgZWLBvpfbIl4RpVkmExKhhLg8se7UAiWUfCBfimLELDRA=="
        }
        params = {
            "ST": isbn,
            "DSF": "Y"
        }

        response = requests.get(search_url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        first_result = soup.select_one("a.book-grid-item")
        if not first_result or not first_result.get("href"):
            return None

        detail_url = "https://bnk.kpipa.or.kr" + first_result["href"]
        detail_res = requests.get(detail_url, headers=headers, timeout=10)
        detail_res.raise_for_status()
        detail_soup = BeautifulSoup(detail_res.text, "html.parser")

        dt_tag = detail_soup.find("dt", string=lambda t: t and "ì¶œíŒì‚¬" in t)
        if not dt_tag:
            return None

        dd_tag = dt_tag.find_next_sibling("dd")
        if not dd_tag:
            return None

        full_text = dd_tag.get_text(strip=True)
        publisher_main = full_text.split(" / ")[0]  # ãˆœë‹¤ì‚°ë¶ìŠ¤
        return publisher_main

    except Exception as e:
        st.error("âŒ [ISBN ê²€ìƒ‰ ì˜¤ë¥˜]")
        st.exception(e)
        return None

# 2ï¸âƒ£ ì¶œíŒì‚¬ëª… â†’ ì¶œíŒì‚¬ëª… ë° ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ì—…ë°ì´íŠ¸ëœ ì„ íƒì ë°˜ì˜)
def get_publisher_location(publisher_name):
    try:
        search_url = "https://bnk.kpipa.or.kr/home/v3/addition/adiPblshrInfoList"
        headers = {
            "User-Agent": "Mozilla/5.0",
            "Referer": "https://bnk.kpipa.or.kr/"
        }
        params = {
            "ST": publisher_name
        }

        response = requests.get(search_url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # í…Œì´ë¸”ì—ì„œ ì²« ë²ˆì§¸ ê²°ê³¼ í–‰ ì„ íƒ
        row = soup.select_one("table.table.srch tbody tr")
        if not row:
            return None, None

        td_list = row.find_all("td")
        if len(td_list) < 3:
            return None, None

        publisher = td_list[1].get_text(strip=True)  # ì¶œíŒì‚¬ëª…
        location = td_list[2].get_text(strip=True)   # ì§€ì—­

        return publisher, location

    except Exception as e:
        st.error("âŒ [ì¶œíŒì‚¬ ì§€ì—­ ê²€ìƒ‰ ì˜¤ë¥˜]")
        st.exception(e)
        return None, None

# â–¶ï¸ Streamlit UI
st.title("ğŸ“š ISBN â†’ ì¶œíŒì‚¬ ë° ì§€ì—­ ì •ë³´ ì¶”ì¶œê¸°")

isbn_input = st.text_input("ğŸ” ISBNì„ ì…ë ¥í•˜ì„¸ìš”")

if st.button("ì •ë³´ ì¶”ì¶œí•˜ê¸°"):
    if isbn_input.strip():
        with st.spinner("1ï¸âƒ£ ISBNìœ¼ë¡œ ì¶œíŒì‚¬ëª… ê²€ìƒ‰ ì¤‘..."):
            publisher = get_publisher_name_from_isbn(isbn_input.strip())

        if publisher:
            st.success(f"ğŸ“˜ 1ì°¨ ê²°ê³¼ - ì¶œíŒì‚¬ëª…: {publisher}")

            with st.spinner("2ï¸âƒ£ ì¶œíŒì‚¬ëª…ìœ¼ë¡œ ì¶œíŒì‚¬ëª… ë° ì§€ì—­ ê²€ìƒ‰ ì¤‘..."):
                pub_name, location = get_publisher_location(publisher)

            if pub_name and location:
                st.success(f"ğŸ“š 2ì°¨ ê²°ê³¼ - ì¶œíŒì‚¬ëª…: {pub_name}")
                st.success(f"ğŸ“ ì§€ì—­: {location}")
            else:
                st.warning("âš ï¸ ì¶œíŒì‚¬ ì§€ì—­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ISBNìœ¼ë¡œë¶€í„° ì¶œíŒì‚¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ISBNì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
